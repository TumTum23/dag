package dsync

import (
	"context"
	"fmt"

	"github.com/qri-io/dag"

	"gx/ipfs/QmPSQnBKM9g7BaUcZCvswUJVscQ1ipjmwxN5PXCjkp9EQ7/go-cid"
	ipld "gx/ipfs/QmR7TcHkR9nxkUorfi8XMTAMLUK7GiP64TWWBzY3aacc1o/go-ipld-format"
)

// NewSend gets a local path to a remote place using a local NodeGetter and a remote
func NewSend(ctx context.Context, lng ipld.NodeGetter, mfst *dag.Manifest, remote Remote) (*Send, error) {
	parallelism := defaultSendParallelism
	if len(mfst.Nodes) < parallelism {
		parallelism = len(mfst.Nodes)
	}

	ps := &Send{
		ctx:         ctx,
		mfst:        mfst,
		lng:         lng,
		remote:      remote,
		parallelism: parallelism,
		blocksCh:    make(chan string),
		progCh:      make(chan dag.Completion),
		responses:   make(chan Response),
		retries:     make(chan string),
	}
	return ps, nil
}

// Send coordinates requesting & sending a manifest to a remote, tracking progress and state
type Send struct {
	sid         string          // session ID for this push, generated by remote
	ctx         context.Context // session context
	mfst        *dag.Manifest   // manifest we're sending
	diff        *dag.Manifest   // returned difference
	lng         ipld.NodeGetter // local NodeGetter (Block Getter)
	remote      Remote          // place we're sending to
	parallelism int             // number of "tracks" for sending along
	prog        dag.Completion  // progress state
	progCh      chan dag.Completion
	blocksCh    chan string
	responses   chan Response
	retries     chan string
}

// Do executes the send, blocking until complete
func (snd *Send) Do() (err error) {
	snd.sid, snd.diff, err = snd.remote.ReqSend(snd.mfst)
	if err != nil {
		return err
	}

	snd.prog = dag.NewCompletion(snd.mfst, snd.diff)
	go snd.completionChanged()
	// defer close(snd.progCh)

	// response said we have nothing to send. all done
	if len(snd.diff.Nodes) == 0 {
		return nil
	}

	// create senders
	sends := make([]sender, snd.parallelism)
	for i := 0; i < snd.parallelism; i++ {
		sends[i] = sender{
			id:        i,
			sid:       snd.sid,
			ctx:       snd.ctx,
			blocksCh:  snd.blocksCh,
			responses: snd.responses,
			lng:       snd.lng,
			remote:    snd.remote,
			stopCh:    make(chan bool),
		}
		go sends[i].start()
	}

	errCh := make(chan error)

	// receive block responses
	go func(sends []sender, errCh chan error) {
		// handle *all* responses from senders. it's very important that this loop
		// never block, so all responses are handled in their own goroutine
		for res := range snd.responses {
			go func(r Response) {
				switch r.Status {
				case StatusOk:
					// this is the only place we should modify progress after creation
					for i, hash := range snd.mfst.Nodes {
						if r.Hash == hash {
							snd.prog[i] = 100
						}
					}
					go snd.completionChanged()
					if snd.prog.Complete() {
						errCh <- nil
						return
					}
				case StatusErrored:
					fmt.Println(r.Err)
					errCh <- r.Err
					for _, s := range sends {
						s.stop()
					}
				case StatusRetry:
					snd.retries <- r.Hash
				}
			}(res)
		}
	}(sends, errCh)

	go func(errCh chan error) {
		retries := 0
		for hash := range snd.retries {
			retries++
			if retries == maxRetries {
				for _, s := range sends {
					s.stop()
				}
				errCh <- fmt.Errorf("max %d retries reached", retries)
				return
			}
			snd.blocksCh <- hash
		}
	}(errCh)

	// fill queue with missing blocks to kick off the send
	go func() {
		for _, hash := range snd.diff.Nodes {
			snd.blocksCh <- hash
		}
	}()

	// block until send on errCh
	return <-errCh
}

// Completion returns a read-only channel of updates to completion
func (snd *Send) Completion() <-chan dag.Completion {
	return snd.progCh
}

func (snd *Send) completionChanged() {
	snd.progCh <- snd.prog
}

// sender is a parallelizable, stateless struct that sends blocks
type sender struct {
	id        int
	sid       string
	ctx       context.Context
	lng       ipld.NodeGetter
	remote    Remote
	blocksCh  chan string
	responses chan Response
	stopCh    chan bool
}

func (s sender) start() {
	for {
		select {
		case hash := <-s.blocksCh:
			// here we're syncronizing multiple channels in a select, and in this case
			// we're (probably) firing off a blocking call to s.remote.PutBlock that's
			// waiting on a network response. This can prevent reading on stopCh & ctx.Done
			// which is very bad, so we fire a goroutine to prevent the select loop from
			// ever blocking. Concurrency is fun!
			go func() {
				id, err := cid.Parse(hash)
				if err != nil {
					s.responses <- Response{
						Hash:   hash,
						Status: StatusErrored,
						Err:    err,
					}
				}
				node, err := s.lng.Get(s.ctx, id)
				if err != nil {
					s.responses <- Response{
						Hash:   hash,
						Status: StatusErrored,
						Err:    err,
					}
					return
				}
				s.responses <- s.remote.PutBlock(s.sid, hash, node.RawData())
			}()
		case <-s.stopCh:
			return
		case <-s.ctx.Done():
			return
		}
	}
}

func (s sender) stop() {
	go func() {
		s.stopCh <- true
	}()
}
